{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Battle of the Languages**\n",
    "here is our code, blah blah blah, we can write more stuff here later\n",
    "please feel free to play with the groupings and cells, I just did some initial stuff I thought  might be helpful, but it might need to be broken up more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Data from the various databases:\n",
    "\n",
    "https://github.com/festvox/datasets-CMU_Wilderness One of the ones Emily recommended, has like 700 languages, seems like it was mined from people reading the new testament. has polish, spanish, english, (probably has greek but it's labeled by the language in that language so I was not positive what I was looking for)\n",
    "\n",
    "https://openslr.org/resources.php The other one Emily recommended instead of the UPenn one, had a brief look and seems like it might be more helpful for spanish/english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR FILEPATH HERE\n",
    "FILEPATH = \"/Users/eviprousanidou/Desktop/BC/Natural Language Programming/final/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "import numpy as np\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "import parselmouth, matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(wav_file):\n",
    "    # get duration, mean pitch, mean intensity\n",
    "    sound = parselmouth.Sound(wav_file)\n",
    "    # pitch\n",
    "    pitch = call(sound, \"To Pitch\", 0, 75, 600) \n",
    "    \n",
    "    # new ==============\n",
    "    pitch_stdev = call(pitch, \"Get standard deviation\", 0, 0, \"Hertz\")\n",
    "    \n",
    "    mean_pitch = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "    min_pitch = call(pitch, \"Get minimum\", 0, 0, \"Hertz\", \"Parabolic\")\n",
    "    max_pitch = call(pitch, \"Get maximum\", 0, 0, \"Hertz\", \"Parabolic\")\n",
    "    \n",
    "    # intensity\n",
    "    intensity = call(sound, \"To Intensity\", 75, 0, \"yes\")\n",
    "\n",
    "    # new ==============\n",
    "    intensity_stdev = call(intensity, \"Get standard deviation\", 0, 0)\n",
    "    \n",
    "    mean_intensity = call(intensity, \"Get mean\", 0, 0, \"energy\")\n",
    "    min_intensity = call(intensity, \"Get minimum\", 0, 0, \"Parabolic\")\n",
    "    max_intensity = call(intensity, \"Get maximum\", 0, 0, \"Parabolic\")\n",
    "    \n",
    "\n",
    "    duration = call(sound, \"Get total duration\")\n",
    "\n",
    "    # get mean features for vowels and consonants\n",
    "    formant = call(sound, \"To Formant (burg)\", 0, 5, 5500, 0.025, 50)\n",
    "    tg_file = re.sub(\"wav\", \"TextGrid\", wav_file)\n",
    "    textgrid = call(\"Read from file\", tg_file)\n",
    "    intv = call(textgrid, \"Get number of intervals\", 1)\n",
    "    \n",
    "    # new ==============\n",
    "    # get mfccs\n",
    "    mfccs = call(sound, \"To MFCC\", 12, 0.015, 0.005, 100, 100, 0).to_array()\n",
    "    mfccs_avg = [np.mean(mfccs[i]) for i in range(13)]\n",
    "    \n",
    "#     vowels = 0\n",
    "#     consonants = 0\n",
    "#     f1_vowels = 0\n",
    "#     dur_vowels = 0\n",
    "    \n",
    "\n",
    "\n",
    "#     for i in range(1, intv):\n",
    "#         phone = call(textgrid, \"Get label of interval\", 1, i)\n",
    "#         # vowels\n",
    "#         if phone == 'sil': continue\n",
    "#         if re.match('[AEIOU]', phone):\n",
    "#             vowels += 1\n",
    "#             vowel_onset = call(textgrid, \"Get starting point\", 1, i)\n",
    "#             vowel_offset = call(textgrid, \"Get end point\", 1, i)\n",
    "#             midpoint = vowel_onset + ((vowel_offset - vowel_onset) / 2)\n",
    "#             f1_vowels += call(formant, \"Get value at time\", 1, midpoint, \"Hertz\", \"Linear\")\n",
    "#             dur_vowels += vowel_offset - vowel_onset\n",
    "    \n",
    "#     f1_vowels = f1_vowels / vowels if vowels > 0 else 0\n",
    "#     dur_vowels = dur_vowels / vowels if vowels > 0 else 0\n",
    "    \n",
    "    \n",
    "\n",
    "    results = [\n",
    "                pitch_stdev,\n",
    "                mean_pitch, \n",
    "                min_pitch,\n",
    "                max_pitch,\n",
    "                intensity_stdev,\n",
    "                mean_intensity, \n",
    "                min_intensity,\n",
    "                max_intensity,\n",
    "                duration,\n",
    "                mfcc_avg,\n",
    "#                 f1_vowels, \n",
    "#                 dur_vowels,\n",
    "            ]\n",
    "   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read Greek Data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "greek=[]\n",
    "\n",
    "for wav_file in glob.glob(join(FILEPATH, \"data/Greek/*.wav\")):\n",
    "    \n",
    "    # print progress\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(counter, wav_file)\n",
    "\n",
    "    results = getFeatures(wav_file)\n",
    "    greek.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read Polish / Czech Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "czech=[]\n",
    "\n",
    "for wav_file in glob.glob(join(FILEPATH, \"data/Czech/*.wav\")):\n",
    "    \n",
    "    # print progress\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(counter, wav_file)\n",
    "\n",
    "    results = getFeatures(wav_file)\n",
    "    czech.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read Spanish Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "spanish=[]\n",
    "\n",
    "for wav_file in glob.glob(join(FILEPATH, \"data/Spanish/*.wav\")):\n",
    "    \n",
    "    # print progress\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(counter, wav_file)\n",
    "\n",
    "    results = getFeatures(wav_file)\n",
    "    spanish.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Read English Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0 \n",
    "\n",
    "english=[]\n",
    "\n",
    "for wav_file in glob.glob(join(FILEPATH, \"data/English/*.wav\")):\n",
    "    \n",
    "    # print progress\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(counter, wav_file)\n",
    "\n",
    "    results = getFeatures(wav_file)\n",
    "    english.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Feature Selection\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Comment out any features we don't want to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = [\n",
    "    0, # pitch_stdev\n",
    "    1, # mean_pitch\n",
    "    2, # min_pitch\n",
    "    3, # max_pitch\n",
    "    4, # intensity_stdev\n",
    "    5, # mean_intensity\n",
    "    6, # min_intensity\n",
    "    7, # max_intensity\n",
    "    8, # duration\n",
    "    9, # mfcc_avg\n",
    "]\n",
    "\n",
    "npdata = npdata[:, selection]\n",
    "npdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scoring Metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select scoring metrics\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models to test\n",
    "models = [\n",
    "            GaussianNB(), \n",
    "            QuadraticDiscriminantAnalysis(),\n",
    "            RandomForestClassifier(max_depth=4),\n",
    "            RandomForestClassifier(max_depth=6),\n",
    "            RandomForestClassifier(max_depth=8),\n",
    "            RandomForestClassifier(max_depth=10),\n",
    "            AdaBoostClassifier(n_estimators=100),\n",
    "            MLPClassifier(max_iter=300),\n",
    "            DecisionTreeClassifier(), \n",
    "            LinearSVC(), \n",
    "            LogisticRegression(),\n",
    "            KNeighborsClassifier(n_neighbors=3),\n",
    "            KNeighborsClassifier(n_neighbors=5),\n",
    "            KNeighborsClassifier(n_neighbors=7),\n",
    "            KNeighborsClassifier(n_neighbors=9),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test each Model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "\n",
    "    # print model name\n",
    "    model_name = str(type(model))\n",
    "    model_name = model_name[model_name.rfind('.')+1:-2]\n",
    "    print('\\n' + model_name + '\\n')\n",
    "\n",
    "    # train and cross validate with 5 folds\n",
    "    scores = cross_validate(model, npdata, nptarget, cv=5, scoring=scoring_metrics)\n",
    "    for score_name, score_value in scores.items():\n",
    "        if \"test\" in score_name:\n",
    "            print(score_name, \"\\t\", np.round(np.mean(score_value), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling said data to compatible formats and whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction and beyond..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
